Results saved to: ./data/00000-val-train
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 48, 48, 3)]  0           []                               
                                                                                                  
 data_augmentation (Sequential)  (None, 48, 48, 3)   0           ['input_1[0][0]']                
                                                                                                  
 patches_1 (Patches)            (None, None, 48)     0           ['data_augmentation[0][0]']      
                                                                                                  
 patch_encoder (PatchEncoder)   (None, 144, 32)      6176        ['patches_1[0][0]']              
                                                                                                  
 layer_normalization (LayerNorm  (None, 144, 32)     64          ['patch_encoder[0][0]']          
 alization)                                                                                       
                                                                                                  
 multi_head_attention (MultiHea  (None, 144, 32)     25184       ['layer_normalization[0][0]',    
 dAttention)                                                      'layer_normalization[0][0]']    
                                                                                                  
 add (Add)                      (None, 144, 32)      0           ['multi_head_attention[0][0]',   
                                                                  'patch_encoder[0][0]']          
                                                                                                  
 layer_normalization_1 (LayerNo  (None, 144, 32)     64          ['add[0][0]']                    
 rmalization)                                                                                     
                                                                                                  
 dense_1 (Dense)                (None, 144, 64)      2112        ['layer_normalization_1[0][0]']  
                                                                                                  
 dropout (Dropout)              (None, 144, 64)      0           ['dense_1[0][0]']                
                                                                                                  
 dense_2 (Dense)                (None, 144, 32)      2080        ['dropout[0][0]']                
                                                                                                  
 dropout_1 (Dropout)            (None, 144, 32)      0           ['dense_2[0][0]']                
                                                                                                  
 add_1 (Add)                    (None, 144, 32)      0           ['dropout_1[0][0]',              
                                                                  'add[0][0]']                    
                                                                                                  
 layer_normalization_2 (LayerNo  (None, 144, 32)     64          ['add_1[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_1 (MultiH  (None, 144, 32)     25184       ['layer_normalization_2[0][0]',  
 eadAttention)                                                    'layer_normalization_2[0][0]']  
                                                                                                  
 add_2 (Add)                    (None, 144, 32)      0           ['multi_head_attention_1[0][0]', 
                                                                  'add_1[0][0]']                  
                                                                                                  
 layer_normalization_3 (LayerNo  (None, 144, 32)     64          ['add_2[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_3 (Dense)                (None, 144, 64)      2112        ['layer_normalization_3[0][0]']  
                                                                                                  
 dropout_2 (Dropout)            (None, 144, 64)      0           ['dense_3[0][0]']                
                                                                                                  
 dense_4 (Dense)                (None, 144, 32)      2080        ['dropout_2[0][0]']              
                                                                                                  
 dropout_3 (Dropout)            (None, 144, 32)      0           ['dense_4[0][0]']                
                                                                                                  
 add_3 (Add)                    (None, 144, 32)      0           ['dropout_3[0][0]',              
                                                                  'add_2[0][0]']                  
                                                                                                  
 layer_normalization_4 (LayerNo  (None, 144, 32)     64          ['add_3[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_2 (MultiH  (None, 144, 32)     25184       ['layer_normalization_4[0][0]',  
 eadAttention)                                                    'layer_normalization_4[0][0]']  
                                                                                                  
 add_4 (Add)                    (None, 144, 32)      0           ['multi_head_attention_2[0][0]', 
                                                                  'add_3[0][0]']                  
                                                                                                  
 layer_normalization_5 (LayerNo  (None, 144, 32)     64          ['add_4[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_5 (Dense)                (None, 144, 64)      2112        ['layer_normalization_5[0][0]']  
                                                                                                  
 dropout_4 (Dropout)            (None, 144, 64)      0           ['dense_5[0][0]']                
                                                                                                  
 dense_6 (Dense)                (None, 144, 32)      2080        ['dropout_4[0][0]']              
                                                                                                  
 dropout_5 (Dropout)            (None, 144, 32)      0           ['dense_6[0][0]']                
                                                                                                  
 add_5 (Add)                    (None, 144, 32)      0           ['dropout_5[0][0]',              
                                                                  'add_4[0][0]']                  
                                                                                                  
 layer_normalization_6 (LayerNo  (None, 144, 32)     64          ['add_5[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_3 (MultiH  (None, 144, 32)     25184       ['layer_normalization_6[0][0]',  
 eadAttention)                                                    'layer_normalization_6[0][0]']  
                                                                                                  
 add_6 (Add)                    (None, 144, 32)      0           ['multi_head_attention_3[0][0]', 
                                                                  'add_5[0][0]']                  
                                                                                                  
 layer_normalization_7 (LayerNo  (None, 144, 32)     64          ['add_6[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_7 (Dense)                (None, 144, 64)      2112        ['layer_normalization_7[0][0]']  
                                                                                                  
 dropout_6 (Dropout)            (None, 144, 64)      0           ['dense_7[0][0]']                
                                                                                                  
 dense_8 (Dense)                (None, 144, 32)      2080        ['dropout_6[0][0]']              
                                                                                                  
 dropout_7 (Dropout)            (None, 144, 32)      0           ['dense_8[0][0]']                
                                                                                                  
 add_7 (Add)                    (None, 144, 32)      0           ['dropout_7[0][0]',              
                                                                  'add_6[0][0]']                  
                                                                                                  
 layer_normalization_8 (LayerNo  (None, 144, 32)     64          ['add_7[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 flatten (Flatten)              (None, 4608)         0           ['layer_normalization_8[0][0]']  
                                                                                                  
 dropout_8 (Dropout)            (None, 4608)         0           ['flatten[0][0]']                
                                                                                                  
 dense_9 (Dense)                (None, 512)          2359808     ['dropout_8[0][0]']              
                                                                                                  
 dropout_9 (Dropout)            (None, 512)          0           ['dense_9[0][0]']                
                                                                                                  
 dense_10 (Dense)               (None, 256)          131328      ['dropout_9[0][0]']              
                                                                                                  
 dropout_10 (Dropout)           (None, 256)          0           ['dense_10[0][0]']               
                                                                                                  
 dense_11 (Dense)               (None, 200)          51400       ['dropout_10[0][0]']             
                                                                                                  
==================================================================================================
Total params: 2,666,792
Trainable params: 2,666,792
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
645/645 [==============================] - 45s 52ms/step - loss: 4.6746 - accuracy: 0.0614 - precision: 0.5110 - recall: 0.0172 - f1_score: 0.0318 - val_loss: 2.8885 - val_accuracy: 0.3346 - val_precision: 0.9305 - val_recall: 0.0864 - val_f1_score: 0.1551 - lr: 0.0010
Epoch 2/100
645/645 [==============================] - 37s 57ms/step - loss: 3.0862 - accuracy: 0.2370 - precision: 0.6266 - recall: 0.1186 - f1_score: 0.1955 - val_loss: 1.6892 - val_accuracy: 0.5485 - val_precision: 0.9130 - val_recall: 0.3128 - val_f1_score: 0.4643 - lr: 0.0010
Epoch 3/100
645/645 [==============================] - 34s 52ms/step - loss: 2.3721 - accuracy: 0.3655 - precision: 0.7119 - recall: 0.2151 - f1_score: 0.3272 - val_loss: 1.2636 - val_accuracy: 0.6716 - val_precision: 0.9354 - val_recall: 0.4713 - val_f1_score: 0.6251 - lr: 0.0010
Epoch 4/100
645/645 [==============================] - 33s 51ms/step - loss: 1.8597 - accuracy: 0.4867 - precision: 0.7691 - recall: 0.3190 - f1_score: 0.4473 - val_loss: 0.9677 - val_accuracy: 0.7461 - val_precision: 0.9477 - val_recall: 0.5872 - val_f1_score: 0.7243 - lr: 0.0010
Epoch 5/100
645/645 [==============================] - 33s 52ms/step - loss: 1.5348 - accuracy: 0.5710 - precision: 0.8026 - recall: 0.4130 - f1_score: 0.5425 - val_loss: 0.7648 - val_accuracy: 0.7883 - val_precision: 0.9369 - val_recall: 0.6747 - val_f1_score: 0.7836 - lr: 0.0010
Epoch 6/100
645/645 [==============================] - 33s 52ms/step - loss: 1.3139 - accuracy: 0.6320 - precision: 0.8280 - recall: 0.4910 - f1_score: 0.6142 - val_loss: 0.6670 - val_accuracy: 0.8165 - val_precision: 0.9383 - val_recall: 0.7161 - val_f1_score: 0.8115 - lr: 0.0010
Epoch 7/100
645/645 [==============================] - 34s 52ms/step - loss: 1.1759 - accuracy: 0.6644 - precision: 0.8361 - recall: 0.5361 - f1_score: 0.6514 - val_loss: 0.5655 - val_accuracy: 0.8401 - val_precision: 0.9359 - val_recall: 0.7669 - val_f1_score: 0.8425 - lr: 0.0010
Epoch 8/100
645/645 [==============================] - 36s 55ms/step - loss: 1.0673 - accuracy: 0.6950 - precision: 0.8504 - recall: 0.5812 - f1_score: 0.6886 - val_loss: 0.5327 - val_accuracy: 0.8521 - val_precision: 0.9473 - val_recall: 0.7743 - val_f1_score: 0.8514 - lr: 0.0010
Epoch 9/100
645/645 [==============================] - 34s 52ms/step - loss: 0.9805 - accuracy: 0.7204 - precision: 0.8573 - recall: 0.6144 - f1_score: 0.7147 - val_loss: 0.4514 - val_accuracy: 0.8732 - val_precision: 0.9487 - val_recall: 0.8154 - val_f1_score: 0.8764 - lr: 0.0010
Epoch 10/100
645/645 [==============================] - 33s 52ms/step - loss: 0.9074 - accuracy: 0.7386 - precision: 0.8652 - recall: 0.6451 - f1_score: 0.7376 - val_loss: 0.4468 - val_accuracy: 0.8739 - val_precision: 0.9488 - val_recall: 0.8144 - val_f1_score: 0.8761 - lr: 0.0010
Epoch 11/100
645/645 [==============================] - 34s 52ms/step - loss: 0.8590 - accuracy: 0.7525 - precision: 0.8707 - recall: 0.6628 - f1_score: 0.7515 - val_loss: 0.3977 - val_accuracy: 0.8823 - val_precision: 0.9519 - val_recall: 0.8376 - val_f1_score: 0.8905 - lr: 0.0010
Epoch 12/100
645/645 [==============================] - 33s 52ms/step - loss: 0.8193 - accuracy: 0.7655 - precision: 0.8742 - recall: 0.6821 - f1_score: 0.7651 - val_loss: 0.3671 - val_accuracy: 0.8934 - val_precision: 0.9493 - val_recall: 0.8509 - val_f1_score: 0.8971 - lr: 0.0010
Epoch 13/100
645/645 [==============================] - 36s 56ms/step - loss: 0.7694 - accuracy: 0.7773 - precision: 0.8774 - recall: 0.7013 - f1_score: 0.7786 - val_loss: 0.3378 - val_accuracy: 0.9047 - val_precision: 0.9585 - val_recall: 0.8715 - val_f1_score: 0.9124 - lr: 0.0010
Epoch 14/100
645/645 [==============================] - 34s 52ms/step - loss: 0.7467 - accuracy: 0.7832 - precision: 0.8781 - recall: 0.7101 - f1_score: 0.7842 - val_loss: 0.3225 - val_accuracy: 0.9033 - val_precision: 0.9549 - val_recall: 0.8706 - val_f1_score: 0.9109 - lr: 0.0010
Epoch 15/100
645/645 [==============================] - 34s 53ms/step - loss: 0.7275 - accuracy: 0.7940 - precision: 0.8863 - recall: 0.7213 - f1_score: 0.7944 - val_loss: 0.3414 - val_accuracy: 0.9029 - val_precision: 0.9615 - val_recall: 0.8643 - val_f1_score: 0.9098 - lr: 0.0010
Epoch 16/100
645/645 [==============================] - 33s 52ms/step - loss: 0.7070 - accuracy: 0.7991 - precision: 0.8882 - recall: 0.7297 - f1_score: 0.8002 - val_loss: 0.2945 - val_accuracy: 0.9141 - val_precision: 0.9537 - val_recall: 0.8927 - val_f1_score: 0.9218 - lr: 0.0010
Epoch 17/100
645/645 [==============================] - 33s 52ms/step - loss: 0.6748 - accuracy: 0.8067 - precision: 0.8914 - recall: 0.7421 - f1_score: 0.8091 - val_loss: 0.3598 - val_accuracy: 0.9004 - val_precision: 0.9562 - val_recall: 0.8610 - val_f1_score: 0.9055 - lr: 0.0010
Epoch 18/100
645/645 [==============================] - 33s 51ms/step - loss: 0.6563 - accuracy: 0.8122 - precision: 0.8946 - recall: 0.7503 - f1_score: 0.8151 - val_loss: 0.3325 - val_accuracy: 0.9059 - val_precision: 0.9682 - val_recall: 0.8593 - val_f1_score: 0.9105 - lr: 0.0010
Epoch 19/100
645/645 [==============================] - 34s 53ms/step - loss: 0.6378 - accuracy: 0.8194 - precision: 0.8973 - recall: 0.7578 - f1_score: 0.8210 - val_loss: 0.2826 - val_accuracy: 0.9191 - val_precision: 0.9647 - val_recall: 0.8879 - val_f1_score: 0.9248 - lr: 0.0010
Epoch 20/100
645/645 [==============================] - 36s 56ms/step - loss: 0.6251 - accuracy: 0.8223 - precision: 0.8962 - recall: 0.7640 - f1_score: 0.8241 - val_loss: 0.2722 - val_accuracy: 0.9218 - val_precision: 0.9595 - val_recall: 0.8992 - val_f1_score: 0.9279 - lr: 0.0010
Epoch 21/100
645/645 [==============================] - 36s 56ms/step - loss: 0.6074 - accuracy: 0.8263 - precision: 0.8983 - recall: 0.7710 - f1_score: 0.8291 - val_loss: 0.2425 - val_accuracy: 0.9279 - val_precision: 0.9636 - val_recall: 0.9030 - val_f1_score: 0.9318 - lr: 0.0010
Epoch 22/100
645/645 [==============================] - 33s 52ms/step - loss: 0.5766 - accuracy: 0.8339 - precision: 0.9026 - recall: 0.7805 - f1_score: 0.8365 - val_loss: 0.2323 - val_accuracy: 0.9295 - val_precision: 0.9656 - val_recall: 0.9068 - val_f1_score: 0.9354 - lr: 9.0484e-04
Epoch 23/100
645/645 [==============================] - 36s 56ms/step - loss: 0.5569 - accuracy: 0.8410 - precision: 0.9087 - recall: 0.7901 - f1_score: 0.8447 - val_loss: 0.2305 - val_accuracy: 0.9309 - val_precision: 0.9650 - val_recall: 0.9078 - val_f1_score: 0.9351 - lr: 8.1873e-04
Epoch 24/100
645/645 [==============================] - 34s 52ms/step - loss: 0.5259 - accuracy: 0.8482 - precision: 0.9092 - recall: 0.7990 - f1_score: 0.8499 - val_loss: 0.2077 - val_accuracy: 0.9394 - val_precision: 0.9678 - val_recall: 0.9207 - val_f1_score: 0.9431 - lr: 7.4082e-04
Epoch 25/100
645/645 [==============================] - 33s 52ms/step - loss: 0.5032 - accuracy: 0.8550 - precision: 0.9132 - recall: 0.8084 - f1_score: 0.8571 - val_loss: 0.2221 - val_accuracy: 0.9338 - val_precision: 0.9641 - val_recall: 0.9090 - val_f1_score: 0.9359 - lr: 6.7032e-04
Epoch 26/100
645/645 [==============================] - 36s 56ms/step - loss: 0.4904 - accuracy: 0.8560 - precision: 0.9145 - recall: 0.8112 - f1_score: 0.8592 - val_loss: 0.2031 - val_accuracy: 0.9388 - val_precision: 0.9719 - val_recall: 0.9173 - val_f1_score: 0.9433 - lr: 6.0653e-04
Epoch 27/100
645/645 [==============================] - 34s 52ms/step - loss: 0.4665 - accuracy: 0.8638 - precision: 0.9173 - recall: 0.8227 - f1_score: 0.8670 - val_loss: 0.2044 - val_accuracy: 0.9372 - val_precision: 0.9672 - val_recall: 0.9181 - val_f1_score: 0.9415 - lr: 5.4881e-04
Epoch 28/100
645/645 [==============================] - 33s 52ms/step - loss: 0.4595 - accuracy: 0.8669 - precision: 0.9198 - recall: 0.8262 - f1_score: 0.8702 - val_loss: 0.1918 - val_accuracy: 0.9434 - val_precision: 0.9700 - val_recall: 0.9241 - val_f1_score: 0.9467 - lr: 4.9659e-04
Epoch 29/100
645/645 [==============================] - 33s 51ms/step - loss: 0.4487 - accuracy: 0.8696 - precision: 0.9217 - recall: 0.8286 - f1_score: 0.8722 - val_loss: 0.1816 - val_accuracy: 0.9438 - val_precision: 0.9698 - val_recall: 0.9287 - val_f1_score: 0.9489 - lr: 4.4933e-04
Epoch 30/100
645/645 [==============================] - 33s 51ms/step - loss: 0.4255 - accuracy: 0.8765 - precision: 0.9256 - recall: 0.8358 - f1_score: 0.8778 - val_loss: 0.1802 - val_accuracy: 0.9453 - val_precision: 0.9703 - val_recall: 0.9275 - val_f1_score: 0.9485 - lr: 4.0657e-04
Epoch 31/100
645/645 [==============================] - 36s 56ms/step - loss: 0.4186 - accuracy: 0.8774 - precision: 0.9262 - recall: 0.8393 - f1_score: 0.8801 - val_loss: 0.1791 - val_accuracy: 0.9450 - val_precision: 0.9693 - val_recall: 0.9277 - val_f1_score: 0.9482 - lr: 3.6788e-04
Epoch 32/100
645/645 [==============================] - 36s 55ms/step - loss: 0.3965 - accuracy: 0.8844 - precision: 0.9296 - recall: 0.8481 - f1_score: 0.8867 - val_loss: 0.1629 - val_accuracy: 0.9515 - val_precision: 0.9728 - val_recall: 0.9362 - val_f1_score: 0.9543 - lr: 3.3287e-04
Epoch 33/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3927 - accuracy: 0.8861 - precision: 0.9292 - recall: 0.8502 - f1_score: 0.8876 - val_loss: 0.1777 - val_accuracy: 0.9461 - val_precision: 0.9738 - val_recall: 0.9277 - val_f1_score: 0.9503 - lr: 3.0119e-04
Epoch 34/100
645/645 [==============================] - 34s 52ms/step - loss: 0.3832 - accuracy: 0.8862 - precision: 0.9310 - recall: 0.8511 - f1_score: 0.8888 - val_loss: 0.1653 - val_accuracy: 0.9493 - val_precision: 0.9733 - val_recall: 0.9328 - val_f1_score: 0.9528 - lr: 2.7253e-04
Epoch 35/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3766 - accuracy: 0.8895 - precision: 0.9313 - recall: 0.8551 - f1_score: 0.8912 - val_loss: 0.1643 - val_accuracy: 0.9485 - val_precision: 0.9720 - val_recall: 0.9345 - val_f1_score: 0.9530 - lr: 2.4660e-04
Epoch 36/100
645/645 [==============================] - 36s 56ms/step - loss: 0.3677 - accuracy: 0.8931 - precision: 0.9338 - recall: 0.8588 - f1_score: 0.8943 - val_loss: 0.1581 - val_accuracy: 0.9508 - val_precision: 0.9726 - val_recall: 0.9376 - val_f1_score: 0.9549 - lr: 2.2313e-04
Epoch 37/100
645/645 [==============================] - 34s 52ms/step - loss: 0.3642 - accuracy: 0.8922 - precision: 0.9329 - recall: 0.8594 - f1_score: 0.8943 - val_loss: 0.1579 - val_accuracy: 0.9502 - val_precision: 0.9732 - val_recall: 0.9376 - val_f1_score: 0.9552 - lr: 2.0190e-04
Epoch 38/100
645/645 [==============================] - 34s 52ms/step - loss: 0.3611 - accuracy: 0.8933 - precision: 0.9328 - recall: 0.8610 - f1_score: 0.8950 - val_loss: 0.1609 - val_accuracy: 0.9500 - val_precision: 0.9735 - val_recall: 0.9346 - val_f1_score: 0.9538 - lr: 1.8268e-04
Epoch 39/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3452 - accuracy: 0.8980 - precision: 0.9359 - recall: 0.8662 - f1_score: 0.8995 - val_loss: 0.1599 - val_accuracy: 0.9500 - val_precision: 0.9714 - val_recall: 0.9377 - val_f1_score: 0.9544 - lr: 1.6530e-04
Epoch 40/100
645/645 [==============================] - 35s 55ms/step - loss: 0.3534 - accuracy: 0.8956 - precision: 0.9356 - recall: 0.8632 - f1_score: 0.8975 - val_loss: 0.1512 - val_accuracy: 0.9528 - val_precision: 0.9728 - val_recall: 0.9403 - val_f1_score: 0.9564 - lr: 1.4957e-04
Epoch 41/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3471 - accuracy: 0.8959 - precision: 0.9352 - recall: 0.8643 - f1_score: 0.8980 - val_loss: 0.1520 - val_accuracy: 0.9522 - val_precision: 0.9728 - val_recall: 0.9395 - val_f1_score: 0.9560 - lr: 1.3534e-04
Epoch 42/100
645/645 [==============================] - 34s 52ms/step - loss: 0.3392 - accuracy: 0.9008 - precision: 0.9372 - recall: 0.8683 - f1_score: 0.9011 - val_loss: 0.1523 - val_accuracy: 0.9518 - val_precision: 0.9720 - val_recall: 0.9400 - val_f1_score: 0.9559 - lr: 1.2246e-04
Epoch 43/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3302 - accuracy: 0.9024 - precision: 0.9388 - recall: 0.8725 - f1_score: 0.9040 - val_loss: 0.1516 - val_accuracy: 0.9523 - val_precision: 0.9729 - val_recall: 0.9405 - val_f1_score: 0.9566 - lr: 1.1080e-04
Epoch 44/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3341 - accuracy: 0.9014 - precision: 0.9374 - recall: 0.8714 - f1_score: 0.9029 - val_loss: 0.1496 - val_accuracy: 0.9539 - val_precision: 0.9748 - val_recall: 0.9408 - val_f1_score: 0.9576 - lr: 1.0026e-04
Epoch 45/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3319 - accuracy: 0.9012 - precision: 0.9375 - recall: 0.8718 - f1_score: 0.9031 - val_loss: 0.1494 - val_accuracy: 0.9531 - val_precision: 0.9718 - val_recall: 0.9415 - val_f1_score: 0.9566 - lr: 9.0718e-05
Epoch 46/100
645/645 [==============================] - 35s 55ms/step - loss: 0.3335 - accuracy: 0.9006 - precision: 0.9382 - recall: 0.8707 - f1_score: 0.9029 - val_loss: 0.1495 - val_accuracy: 0.9533 - val_precision: 0.9730 - val_recall: 0.9393 - val_f1_score: 0.9560 - lr: 8.2085e-05
Epoch 47/100
645/645 [==============================] - 34s 52ms/step - loss: 0.3252 - accuracy: 0.9025 - precision: 0.9400 - recall: 0.8729 - f1_score: 0.9049 - val_loss: 0.1461 - val_accuracy: 0.9537 - val_precision: 0.9725 - val_recall: 0.9421 - val_f1_score: 0.9572 - lr: 7.4274e-05
Epoch 48/100
645/645 [==============================] - 36s 55ms/step - loss: 0.3215 - accuracy: 0.9043 - precision: 0.9407 - recall: 0.8756 - f1_score: 0.9065 - val_loss: 0.1444 - val_accuracy: 0.9548 - val_precision: 0.9725 - val_recall: 0.9421 - val_f1_score: 0.9572 - lr: 6.7206e-05
Epoch 49/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3290 - accuracy: 0.9017 - precision: 0.9391 - recall: 0.8724 - f1_score: 0.9041 - val_loss: 0.1481 - val_accuracy: 0.9529 - val_precision: 0.9727 - val_recall: 0.9404 - val_f1_score: 0.9564 - lr: 6.0810e-05
Epoch 50/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3249 - accuracy: 0.9028 - precision: 0.9385 - recall: 0.8740 - f1_score: 0.9048 - val_loss: 0.1466 - val_accuracy: 0.9547 - val_precision: 0.9746 - val_recall: 0.9421 - val_f1_score: 0.9582 - lr: 5.5023e-05
Epoch 51/100
645/645 [==============================] - 33s 52ms/step - loss: 0.3188 - accuracy: 0.9053 - precision: 0.9397 - recall: 0.8759 - f1_score: 0.9064 - val_loss: 0.1466 - val_accuracy: 0.9541 - val_precision: 0.9734 - val_recall: 0.9421 - val_f1_score: 0.9577 - lr: 4.9787e-05
Epoch 52/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3259 - accuracy: 0.9038 - precision: 0.9396 - recall: 0.8742 - f1_score: 0.9054 - val_loss: 0.1459 - val_accuracy: 0.9544 - val_precision: 0.9738 - val_recall: 0.9415 - val_f1_score: 0.9575 - lr: 4.5049e-05
Epoch 53/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3181 - accuracy: 0.9055 - precision: 0.9411 - recall: 0.8766 - f1_score: 0.9075 - val_loss: 0.1460 - val_accuracy: 0.9533 - val_precision: 0.9734 - val_recall: 0.9413 - val_f1_score: 0.9572 - lr: 4.0762e-05
Epoch 54/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3151 - accuracy: 0.9060 - precision: 0.9410 - recall: 0.8773 - f1_score: 0.9078 - val_loss: 0.1462 - val_accuracy: 0.9546 - val_precision: 0.9746 - val_recall: 0.9414 - val_f1_score: 0.9578 - lr: 3.6883e-05
Epoch 55/100
645/645 [==============================] - 34s 52ms/step - loss: 0.3209 - accuracy: 0.9049 - precision: 0.9401 - recall: 0.8766 - f1_score: 0.9069 - val_loss: 0.1440 - val_accuracy: 0.9547 - val_precision: 0.9731 - val_recall: 0.9436 - val_f1_score: 0.9583 - lr: 3.3373e-05
Epoch 56/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3166 - accuracy: 0.9063 - precision: 0.9389 - recall: 0.8793 - f1_score: 0.9078 - val_loss: 0.1441 - val_accuracy: 0.9557 - val_precision: 0.9735 - val_recall: 0.9429 - val_f1_score: 0.9581 - lr: 3.0197e-05
Epoch 57/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3114 - accuracy: 0.9067 - precision: 0.9424 - recall: 0.8800 - f1_score: 0.9098 - val_loss: 0.1433 - val_accuracy: 0.9552 - val_precision: 0.9735 - val_recall: 0.9438 - val_f1_score: 0.9585 - lr: 2.7324e-05
Epoch 58/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3045 - accuracy: 0.9098 - precision: 0.9440 - recall: 0.8816 - f1_score: 0.9114 - val_loss: 0.1437 - val_accuracy: 0.9552 - val_precision: 0.9736 - val_recall: 0.9430 - val_f1_score: 0.9582 - lr: 2.4724e-05
Epoch 59/100
645/645 [==============================] - 34s 52ms/step - loss: 0.3184 - accuracy: 0.9057 - precision: 0.9405 - recall: 0.8787 - f1_score: 0.9082 - val_loss: 0.1425 - val_accuracy: 0.9544 - val_precision: 0.9731 - val_recall: 0.9430 - val_f1_score: 0.9580 - lr: 2.2371e-05
Epoch 60/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3069 - accuracy: 0.9089 - precision: 0.9424 - recall: 0.8817 - f1_score: 0.9107 - val_loss: 0.1416 - val_accuracy: 0.9548 - val_precision: 0.9726 - val_recall: 0.9435 - val_f1_score: 0.9580 - lr: 2.0242e-05
Epoch 61/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3065 - accuracy: 0.9087 - precision: 0.9427 - recall: 0.8805 - f1_score: 0.9101 - val_loss: 0.1407 - val_accuracy: 0.9551 - val_precision: 0.9730 - val_recall: 0.9441 - val_f1_score: 0.9585 - lr: 1.8316e-05
Epoch 62/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3127 - accuracy: 0.9080 - precision: 0.9424 - recall: 0.8808 - f1_score: 0.9103 - val_loss: 0.1421 - val_accuracy: 0.9551 - val_precision: 0.9740 - val_recall: 0.9433 - val_f1_score: 0.9585 - lr: 1.6573e-05
Epoch 63/100
645/645 [==============================] - 34s 52ms/step - loss: 0.3110 - accuracy: 0.9078 - precision: 0.9433 - recall: 0.8806 - f1_score: 0.9105 - val_loss: 0.1424 - val_accuracy: 0.9549 - val_precision: 0.9731 - val_recall: 0.9433 - val_f1_score: 0.9581 - lr: 1.4996e-05
Epoch 64/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3066 - accuracy: 0.9103 - precision: 0.9449 - recall: 0.8821 - f1_score: 0.9120 - val_loss: 0.1426 - val_accuracy: 0.9549 - val_precision: 0.9737 - val_recall: 0.9431 - val_f1_score: 0.9583 - lr: 1.3569e-05
Epoch 65/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3109 - accuracy: 0.9091 - precision: 0.9421 - recall: 0.8794 - f1_score: 0.9094 - val_loss: 0.1426 - val_accuracy: 0.9544 - val_precision: 0.9743 - val_recall: 0.9428 - val_f1_score: 0.9584 - lr: 1.2277e-05
Epoch 66/100
645/645 [==============================] - 33s 52ms/step - loss: 0.3102 - accuracy: 0.9085 - precision: 0.9414 - recall: 0.8800 - f1_score: 0.9093 - val_loss: 0.1427 - val_accuracy: 0.9548 - val_precision: 0.9738 - val_recall: 0.9428 - val_f1_score: 0.9582 - lr: 1.1109e-05
Epoch 67/100
645/645 [==============================] - 34s 53ms/step - loss: 0.3078 - accuracy: 0.9077 - precision: 0.9433 - recall: 0.8795 - f1_score: 0.9100 - val_loss: 0.1402 - val_accuracy: 0.9544 - val_precision: 0.9732 - val_recall: 0.9435 - val_f1_score: 0.9583 - lr: 1.0052e-05
Epoch 68/100
645/645 [==============================] - 36s 56ms/step - loss: 0.3077 - accuracy: 0.9084 - precision: 0.9423 - recall: 0.8807 - f1_score: 0.9102 - val_loss: 0.1407 - val_accuracy: 0.9544 - val_precision: 0.9731 - val_recall: 0.9436 - val_f1_score: 0.9583 - lr: 9.0953e-06
Epoch 69/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3073 - accuracy: 0.9092 - precision: 0.9421 - recall: 0.8822 - f1_score: 0.9109 - val_loss: 0.1405 - val_accuracy: 0.9548 - val_precision: 0.9735 - val_recall: 0.9434 - val_f1_score: 0.9583 - lr: 8.2297e-06
Epoch 70/100
645/645 [==============================] - 33s 50ms/step - loss: 0.3058 - accuracy: 0.9100 - precision: 0.9433 - recall: 0.8839 - f1_score: 0.9124 - val_loss: 0.1416 - val_accuracy: 0.9547 - val_precision: 0.9737 - val_recall: 0.9426 - val_f1_score: 0.9581 - lr: 7.4466e-06
Epoch 71/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3047 - accuracy: 0.9093 - precision: 0.9441 - recall: 0.8810 - f1_score: 0.9112 - val_loss: 0.1409 - val_accuracy: 0.9549 - val_precision: 0.9736 - val_recall: 0.9433 - val_f1_score: 0.9583 - lr: 6.7379e-06
Epoch 72/100
645/645 [==============================] - 32s 50ms/step - loss: 0.3058 - accuracy: 0.9082 - precision: 0.9411 - recall: 0.8812 - f1_score: 0.9098 - val_loss: 0.1409 - val_accuracy: 0.9549 - val_precision: 0.9739 - val_recall: 0.9433 - val_f1_score: 0.9584 - lr: 6.0967e-06
Epoch 73/100
645/645 [==============================] - 32s 50ms/step - loss: 0.2986 - accuracy: 0.9110 - precision: 0.9443 - recall: 0.8843 - f1_score: 0.9130 - val_loss: 0.1408 - val_accuracy: 0.9553 - val_precision: 0.9734 - val_recall: 0.9440 - val_f1_score: 0.9586 - lr: 5.5166e-06
Epoch 74/100
645/645 [==============================] - 32s 50ms/step - loss: 0.3058 - accuracy: 0.9090 - precision: 0.9437 - recall: 0.8814 - f1_score: 0.9111 - val_loss: 0.1411 - val_accuracy: 0.9551 - val_precision: 0.9739 - val_recall: 0.9434 - val_f1_score: 0.9585 - lr: 4.9916e-06
Epoch 75/100
645/645 [==============================] - 32s 50ms/step - loss: 0.2952 - accuracy: 0.9126 - precision: 0.9451 - recall: 0.8836 - f1_score: 0.9130 - val_loss: 0.1406 - val_accuracy: 0.9551 - val_precision: 0.9732 - val_recall: 0.9431 - val_f1_score: 0.9581 - lr: 4.5166e-06
Epoch 76/100
645/645 [==============================] - 33s 51ms/step - loss: 0.3015 - accuracy: 0.9095 - precision: 0.9423 - recall: 0.8822 - f1_score: 0.9111 - val_loss: 0.1402 - val_accuracy: 0.9554 - val_precision: 0.9732 - val_recall: 0.9439 - val_f1_score: 0.9585 - lr: 4.0868e-06
Epoch 77/100
645/645 [==============================] - 32s 50ms/step - loss: 0.3043 - accuracy: 0.9093 - precision: 0.9414 - recall: 0.8814 - f1_score: 0.9101 - val_loss: 0.1404 - val_accuracy: 0.9552 - val_precision: 0.9734 - val_recall: 0.9440 - val_f1_score: 0.9586 - lr: 3.6979e-06
Elapsed time: 0:43.46666666666667:28.08