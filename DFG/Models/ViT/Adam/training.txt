Results saved to: ./data/00002-val-train
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_2 (InputLayer)           [(None, 48, 48, 3)]  0           []                               
                                                                                                  
 data_augmentation (Sequential)  (None, 48, 48, 3)   0           ['input_2[0][0]']                
                                                                                                  
 patches_3 (Patches)            (None, None, 48)     0           ['data_augmentation[0][0]']      
                                                                                                  
 patch_encoder_1 (PatchEncoder)  (None, 144, 32)     6176        ['patches_3[0][0]']              
                                                                                                  
 layer_normalization_9 (LayerNo  (None, 144, 32)     64          ['patch_encoder_1[0][0]']        
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_4 (MultiH  (None, 144, 32)     25184       ['layer_normalization_9[0][0]',  
 eadAttention)                                                    'layer_normalization_9[0][0]']  
                                                                                                  
 add_8 (Add)                    (None, 144, 32)      0           ['multi_head_attention_4[0][0]', 
                                                                  'patch_encoder_1[0][0]']        
                                                                                                  
 layer_normalization_10 (LayerN  (None, 144, 32)     64          ['add_8[0][0]']                  
 ormalization)                                                                                    
                                                                                                  
 dense_13 (Dense)               (None, 144, 64)      2112        ['layer_normalization_10[0][0]'] 
                                                                                                  
 dropout_11 (Dropout)           (None, 144, 64)      0           ['dense_13[0][0]']               
                                                                                                  
 dense_14 (Dense)               (None, 144, 32)      2080        ['dropout_11[0][0]']             
                                                                                                  
 dropout_12 (Dropout)           (None, 144, 32)      0           ['dense_14[0][0]']               
                                                                                                  
 add_9 (Add)                    (None, 144, 32)      0           ['dropout_12[0][0]',             
                                                                  'add_8[0][0]']                  
                                                                                                  
 layer_normalization_11 (LayerN  (None, 144, 32)     64          ['add_9[0][0]']                  
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_5 (MultiH  (None, 144, 32)     25184       ['layer_normalization_11[0][0]', 
 eadAttention)                                                    'layer_normalization_11[0][0]'] 
                                                                                                  
 add_10 (Add)                   (None, 144, 32)      0           ['multi_head_attention_5[0][0]', 
                                                                  'add_9[0][0]']                  
                                                                                                  
 layer_normalization_12 (LayerN  (None, 144, 32)     64          ['add_10[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 dense_15 (Dense)               (None, 144, 64)      2112        ['layer_normalization_12[0][0]'] 
                                                                                                  
 dropout_13 (Dropout)           (None, 144, 64)      0           ['dense_15[0][0]']               
                                                                                                  
 dense_16 (Dense)               (None, 144, 32)      2080        ['dropout_13[0][0]']             
                                                                                                  
 dropout_14 (Dropout)           (None, 144, 32)      0           ['dense_16[0][0]']               
                                                                                                  
 add_11 (Add)                   (None, 144, 32)      0           ['dropout_14[0][0]',             
                                                                  'add_10[0][0]']                 
                                                                                                  
 layer_normalization_13 (LayerN  (None, 144, 32)     64          ['add_11[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_6 (MultiH  (None, 144, 32)     25184       ['layer_normalization_13[0][0]', 
 eadAttention)                                                    'layer_normalization_13[0][0]'] 
                                                                                                  
 add_12 (Add)                   (None, 144, 32)      0           ['multi_head_attention_6[0][0]', 
                                                                  'add_11[0][0]']                 
                                                                                                  
 layer_normalization_14 (LayerN  (None, 144, 32)     64          ['add_12[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 dense_17 (Dense)               (None, 144, 64)      2112        ['layer_normalization_14[0][0]'] 
                                                                                                  
 dropout_15 (Dropout)           (None, 144, 64)      0           ['dense_17[0][0]']               
                                                                                                  
 dense_18 (Dense)               (None, 144, 32)      2080        ['dropout_15[0][0]']             
                                                                                                  
 dropout_16 (Dropout)           (None, 144, 32)      0           ['dense_18[0][0]']               
                                                                                                  
 add_13 (Add)                   (None, 144, 32)      0           ['dropout_16[0][0]',             
                                                                  'add_12[0][0]']                 
                                                                                                  
 layer_normalization_15 (LayerN  (None, 144, 32)     64          ['add_13[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_7 (MultiH  (None, 144, 32)     25184       ['layer_normalization_15[0][0]', 
 eadAttention)                                                    'layer_normalization_15[0][0]'] 
                                                                                                  
 add_14 (Add)                   (None, 144, 32)      0           ['multi_head_attention_7[0][0]', 
                                                                  'add_13[0][0]']                 
                                                                                                  
 layer_normalization_16 (LayerN  (None, 144, 32)     64          ['add_14[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 dense_19 (Dense)               (None, 144, 64)      2112        ['layer_normalization_16[0][0]'] 
                                                                                                  
 dropout_17 (Dropout)           (None, 144, 64)      0           ['dense_19[0][0]']               
                                                                                                  
 dense_20 (Dense)               (None, 144, 32)      2080        ['dropout_17[0][0]']             
                                                                                                  
 dropout_18 (Dropout)           (None, 144, 32)      0           ['dense_20[0][0]']               
                                                                                                  
 add_15 (Add)                   (None, 144, 32)      0           ['dropout_18[0][0]',             
                                                                  'add_14[0][0]']                 
                                                                                                  
 layer_normalization_17 (LayerN  (None, 144, 32)     64          ['add_15[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 flatten_1 (Flatten)            (None, 4608)         0           ['layer_normalization_17[0][0]'] 
                                                                                                  
 dropout_19 (Dropout)           (None, 4608)         0           ['flatten_1[0][0]']              
                                                                                                  
 dense_21 (Dense)               (None, 512)          2359808     ['dropout_19[0][0]']             
                                                                                                  
 dropout_20 (Dropout)           (None, 512)          0           ['dense_21[0][0]']               
                                                                                                  
 dense_22 (Dense)               (None, 256)          131328      ['dropout_20[0][0]']             
                                                                                                  
 dropout_21 (Dropout)           (None, 256)          0           ['dense_22[0][0]']               
                                                                                                  
 dense_23 (Dense)               (None, 200)          51400       ['dropout_21[0][0]']             
                                                                                                  
==================================================================================================
Total params: 2,666,792
Trainable params: 2,666,792
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
645/645 [==============================] - 43s 49ms/step - loss: 4.8584 - accuracy: 0.0446 - precision_1: 0.5105 - recall_1: 0.0128 - f1_score: 0.0241 - val_loss: 3.0964 - val_accuracy: 0.2372 - val_precision_1: 0.9113 - val_recall_1: 0.0829 - val_f1_score: 0.1488 - lr: 0.0010
Epoch 2/100
645/645 [==============================] - 31s 47ms/step - loss: 3.2797 - accuracy: 0.2050 - precision_1: 0.6352 - recall_1: 0.1054 - f1_score: 0.1768 - val_loss: 1.8760 - val_accuracy: 0.5063 - val_precision_1: 0.9167 - val_recall_1: 0.2458 - val_f1_score: 0.3849 - lr: 0.0010
Epoch 3/100
645/645 [==============================] - 31s 47ms/step - loss: 2.4469 - accuracy: 0.3413 - precision_1: 0.7082 - recall_1: 0.2074 - f1_score: 0.3168 - val_loss: 1.3760 - val_accuracy: 0.6225 - val_precision_1: 0.9198 - val_recall_1: 0.3944 - val_f1_score: 0.5492 - lr: 0.0010
Epoch 4/100
645/645 [==============================] - 31s 47ms/step - loss: 1.8863 - accuracy: 0.4634 - precision_1: 0.7606 - recall_1: 0.3075 - f1_score: 0.4340 - val_loss: 0.9910 - val_accuracy: 0.7385 - val_precision_1: 0.9445 - val_recall_1: 0.5412 - val_f1_score: 0.6865 - lr: 0.0010
Epoch 5/100
645/645 [==============================] - 31s 48ms/step - loss: 1.5131 - accuracy: 0.5599 - precision_1: 0.7911 - recall_1: 0.4063 - f1_score: 0.5344 - val_loss: 0.7481 - val_accuracy: 0.7854 - val_precision_1: 0.9359 - val_recall_1: 0.6577 - val_f1_score: 0.7717 - lr: 0.0010
Epoch 6/100
645/645 [==============================] - 31s 47ms/step - loss: 1.2374 - accuracy: 0.6305 - precision_1: 0.8198 - recall_1: 0.4987 - f1_score: 0.6180 - val_loss: 0.6005 - val_accuracy: 0.8333 - val_precision_1: 0.9482 - val_recall_1: 0.7296 - val_f1_score: 0.8240 - lr: 0.0010
Epoch 7/100
645/645 [==============================] - 31s 48ms/step - loss: 1.0642 - accuracy: 0.6786 - precision_1: 0.8348 - recall_1: 0.5621 - f1_score: 0.6701 - val_loss: 0.5186 - val_accuracy: 0.8504 - val_precision_1: 0.9504 - val_recall_1: 0.7707 - val_f1_score: 0.8505 - lr: 0.0010
Epoch 8/100
645/645 [==============================] - 31s 47ms/step - loss: 0.9347 - accuracy: 0.7180 - precision_1: 0.8466 - recall_1: 0.6131 - f1_score: 0.7096 - val_loss: 0.4287 - val_accuracy: 0.8773 - val_precision_1: 0.9436 - val_recall_1: 0.8165 - val_f1_score: 0.8750 - lr: 0.0010
Epoch 9/100
645/645 [==============================] - 30s 47ms/step - loss: 0.8385 - accuracy: 0.7436 - precision_1: 0.8590 - recall_1: 0.6570 - f1_score: 0.7434 - val_loss: 0.3769 - val_accuracy: 0.8881 - val_precision_1: 0.9465 - val_recall_1: 0.8412 - val_f1_score: 0.8902 - lr: 0.0010
Epoch 10/100
645/645 [==============================] - 31s 48ms/step - loss: 0.7599 - accuracy: 0.7685 - precision_1: 0.8670 - recall_1: 0.6898 - f1_score: 0.7672 - val_loss: 0.3364 - val_accuracy: 0.8978 - val_precision_1: 0.9555 - val_recall_1: 0.8574 - val_f1_score: 0.9038 - lr: 0.0010
Epoch 11/100
645/645 [==============================] - 30s 47ms/step - loss: 0.7003 - accuracy: 0.7812 - precision_1: 0.8752 - recall_1: 0.7110 - f1_score: 0.7836 - val_loss: 0.3101 - val_accuracy: 0.9095 - val_precision_1: 0.9600 - val_recall_1: 0.8764 - val_f1_score: 0.9162 - lr: 0.0010
Epoch 12/100
645/645 [==============================] - 31s 47ms/step - loss: 0.6476 - accuracy: 0.7969 - precision_1: 0.8808 - recall_1: 0.7341 - f1_score: 0.7999 - val_loss: 0.2799 - val_accuracy: 0.9167 - val_precision_1: 0.9587 - val_recall_1: 0.8899 - val_f1_score: 0.9231 - lr: 0.0010
Epoch 13/100
645/645 [==============================] - 30s 47ms/step - loss: 0.6106 - accuracy: 0.8091 - precision_1: 0.8843 - recall_1: 0.7527 - f1_score: 0.8123 - val_loss: 0.2705 - val_accuracy: 0.9224 - val_precision_1: 0.9632 - val_recall_1: 0.8906 - val_f1_score: 0.9256 - lr: 0.0010
Epoch 14/100
645/645 [==============================] - 30s 47ms/step - loss: 0.5643 - accuracy: 0.8251 - precision_1: 0.8942 - recall_1: 0.7709 - f1_score: 0.8276 - val_loss: 0.2511 - val_accuracy: 0.9210 - val_precision_1: 0.9609 - val_recall_1: 0.8932 - val_f1_score: 0.9259 - lr: 0.0010
Epoch 15/100
645/645 [==============================] - 30s 47ms/step - loss: 0.5441 - accuracy: 0.8282 - precision_1: 0.8937 - recall_1: 0.7790 - f1_score: 0.8319 - val_loss: 0.2233 - val_accuracy: 0.9337 - val_precision_1: 0.9670 - val_recall_1: 0.9059 - val_f1_score: 0.9356 - lr: 0.0010
Epoch 16/100
645/645 [==============================] - 30s 46ms/step - loss: 0.5200 - accuracy: 0.8376 - precision_1: 0.8969 - recall_1: 0.7907 - f1_score: 0.8397 - val_loss: 0.2261 - val_accuracy: 0.9333 - val_precision_1: 0.9630 - val_recall_1: 0.9106 - val_f1_score: 0.9362 - lr: 0.0010
Epoch 17/100
645/645 [==============================] - 30s 47ms/step - loss: 0.4977 - accuracy: 0.8452 - precision_1: 0.9019 - recall_1: 0.8015 - f1_score: 0.8482 - val_loss: 0.2001 - val_accuracy: 0.9398 - val_precision_1: 0.9690 - val_recall_1: 0.9168 - val_f1_score: 0.9423 - lr: 0.0010
Epoch 18/100
645/645 [==============================] - 30s 47ms/step - loss: 0.4676 - accuracy: 0.8535 - precision_1: 0.9053 - recall_1: 0.8128 - f1_score: 0.8559 - val_loss: 0.1918 - val_accuracy: 0.9374 - val_precision_1: 0.9641 - val_recall_1: 0.9209 - val_f1_score: 0.9422 - lr: 0.0010
Epoch 19/100
645/645 [==============================] - 30s 46ms/step - loss: 0.4607 - accuracy: 0.8546 - precision_1: 0.9052 - recall_1: 0.8150 - f1_score: 0.8573 - val_loss: 0.2021 - val_accuracy: 0.9384 - val_precision_1: 0.9671 - val_recall_1: 0.9146 - val_f1_score: 0.9402 - lr: 0.0010
Epoch 20/100
645/645 [==============================] - 30s 47ms/step - loss: 0.4431 - accuracy: 0.8613 - precision_1: 0.9114 - recall_1: 0.8250 - f1_score: 0.8656 - val_loss: 0.1797 - val_accuracy: 0.9439 - val_precision_1: 0.9687 - val_recall_1: 0.9287 - val_f1_score: 0.9484 - lr: 0.0010
Epoch 21/100
645/645 [==============================] - 30s 47ms/step - loss: 0.4269 - accuracy: 0.8670 - precision_1: 0.9132 - recall_1: 0.8324 - f1_score: 0.8706 - val_loss: 0.1916 - val_accuracy: 0.9415 - val_precision_1: 0.9672 - val_recall_1: 0.9253 - val_f1_score: 0.9459 - lr: 0.0010
Epoch 22/100
645/645 [==============================] - 30s 47ms/step - loss: 0.4076 - accuracy: 0.8722 - precision_1: 0.9148 - recall_1: 0.8392 - f1_score: 0.8749 - val_loss: 0.1749 - val_accuracy: 0.9472 - val_precision_1: 0.9688 - val_recall_1: 0.9331 - val_f1_score: 0.9508 - lr: 9.0484e-04
Epoch 23/100
645/645 [==============================] - 30s 47ms/step - loss: 0.3723 - accuracy: 0.8807 - precision_1: 0.9219 - recall_1: 0.8512 - f1_score: 0.8848 - val_loss: 0.1615 - val_accuracy: 0.9512 - val_precision_1: 0.9689 - val_recall_1: 0.9394 - val_f1_score: 0.9541 - lr: 8.1873e-04
Epoch 24/100
645/645 [==============================] - 31s 47ms/step - loss: 0.3546 - accuracy: 0.8891 - precision_1: 0.9269 - recall_1: 0.8608 - f1_score: 0.8923 - val_loss: 0.1486 - val_accuracy: 0.9552 - val_precision_1: 0.9735 - val_recall_1: 0.9404 - val_f1_score: 0.9568 - lr: 7.4082e-04
Epoch 25/100
645/645 [==============================] - 31s 48ms/step - loss: 0.3365 - accuracy: 0.8925 - precision_1: 0.9267 - recall_1: 0.8658 - f1_score: 0.8948 - val_loss: 0.1408 - val_accuracy: 0.9577 - val_precision_1: 0.9733 - val_recall_1: 0.9460 - val_f1_score: 0.9596 - lr: 6.7032e-04
Epoch 26/100
645/645 [==============================] - 31s 47ms/step - loss: 0.3126 - accuracy: 0.9017 - precision_1: 0.9328 - recall_1: 0.8771 - f1_score: 0.9038 - val_loss: 0.1338 - val_accuracy: 0.9583 - val_precision_1: 0.9752 - val_recall_1: 0.9465 - val_f1_score: 0.9608 - lr: 6.0653e-04
Epoch 27/100
645/645 [==============================] - 31s 47ms/step - loss: 0.3003 - accuracy: 0.9042 - precision_1: 0.9353 - recall_1: 0.8813 - f1_score: 0.9073 - val_loss: 0.1274 - val_accuracy: 0.9599 - val_precision_1: 0.9768 - val_recall_1: 0.9479 - val_f1_score: 0.9622 - lr: 5.4881e-04
Epoch 28/100
645/645 [==============================] - 30s 46ms/step - loss: 0.2834 - accuracy: 0.9088 - precision_1: 0.9364 - recall_1: 0.8877 - f1_score: 0.9112 - val_loss: 0.1314 - val_accuracy: 0.9604 - val_precision_1: 0.9772 - val_recall_1: 0.9510 - val_f1_score: 0.9640 - lr: 4.9659e-04
Epoch 29/100
645/645 [==============================] - 30s 47ms/step - loss: 0.2687 - accuracy: 0.9126 - precision_1: 0.9386 - recall_1: 0.8920 - f1_score: 0.9145 - val_loss: 0.1203 - val_accuracy: 0.9621 - val_precision_1: 0.9771 - val_recall_1: 0.9498 - val_f1_score: 0.9634 - lr: 4.4933e-04
Epoch 30/100
645/645 [==============================] - 30s 47ms/step - loss: 0.2538 - accuracy: 0.9173 - precision_1: 0.9411 - recall_1: 0.8972 - f1_score: 0.9184 - val_loss: 0.1208 - val_accuracy: 0.9626 - val_precision_1: 0.9773 - val_recall_1: 0.9534 - val_f1_score: 0.9654 - lr: 4.0657e-04
Epoch 31/100
645/645 [==============================] - 31s 48ms/step - loss: 0.2568 - accuracy: 0.9181 - precision_1: 0.9434 - recall_1: 0.8990 - f1_score: 0.9204 - val_loss: 0.1183 - val_accuracy: 0.9635 - val_precision_1: 0.9772 - val_recall_1: 0.9538 - val_f1_score: 0.9655 - lr: 3.6788e-04
Epoch 32/100
645/645 [==============================] - 31s 49ms/step - loss: 0.2433 - accuracy: 0.9206 - precision_1: 0.9444 - recall_1: 0.9021 - f1_score: 0.9227 - val_loss: 0.1107 - val_accuracy: 0.9633 - val_precision_1: 0.9799 - val_recall_1: 0.9559 - val_f1_score: 0.9679 - lr: 3.3287e-04
Epoch 33/100
645/645 [==============================] - 31s 48ms/step - loss: 0.2279 - accuracy: 0.9247 - precision_1: 0.9469 - recall_1: 0.9074 - f1_score: 0.9265 - val_loss: 0.1154 - val_accuracy: 0.9645 - val_precision_1: 0.9792 - val_recall_1: 0.9534 - val_f1_score: 0.9662 - lr: 3.0119e-04
Epoch 34/100
645/645 [==============================] - 30s 47ms/step - loss: 0.2213 - accuracy: 0.9288 - precision_1: 0.9500 - recall_1: 0.9120 - f1_score: 0.9304 - val_loss: 0.1123 - val_accuracy: 0.9660 - val_precision_1: 0.9788 - val_recall_1: 0.9577 - val_f1_score: 0.9682 - lr: 2.7253e-04
Epoch 35/100
645/645 [==============================] - 30s 47ms/step - loss: 0.2211 - accuracy: 0.9286 - precision_1: 0.9497 - recall_1: 0.9126 - f1_score: 0.9306 - val_loss: 0.1089 - val_accuracy: 0.9677 - val_precision_1: 0.9796 - val_recall_1: 0.9580 - val_f1_score: 0.9688 - lr: 2.4660e-04
Epoch 36/100
645/645 [==============================] - 30s 47ms/step - loss: 0.2076 - accuracy: 0.9319 - precision_1: 0.9517 - recall_1: 0.9169 - f1_score: 0.9338 - val_loss: 0.1086 - val_accuracy: 0.9650 - val_precision_1: 0.9789 - val_recall_1: 0.9580 - val_f1_score: 0.9685 - lr: 2.2313e-04
Epoch 37/100
645/645 [==============================] - 30s 46ms/step - loss: 0.2028 - accuracy: 0.9331 - precision_1: 0.9522 - recall_1: 0.9166 - f1_score: 0.9337 - val_loss: 0.1067 - val_accuracy: 0.9671 - val_precision_1: 0.9782 - val_recall_1: 0.9600 - val_f1_score: 0.9692 - lr: 2.0190e-04
Epoch 38/100
645/645 [==============================] - 30s 46ms/step - loss: 0.2052 - accuracy: 0.9336 - precision_1: 0.9512 - recall_1: 0.9173 - f1_score: 0.9338 - val_loss: 0.1075 - val_accuracy: 0.9691 - val_precision_1: 0.9815 - val_recall_1: 0.9609 - val_f1_score: 0.9712 - lr: 1.8268e-04
Epoch 39/100
645/645 [==============================] - 30s 47ms/step - loss: 0.2020 - accuracy: 0.9333 - precision_1: 0.9518 - recall_1: 0.9180 - f1_score: 0.9345 - val_loss: 0.1005 - val_accuracy: 0.9693 - val_precision_1: 0.9804 - val_recall_1: 0.9605 - val_f1_score: 0.9704 - lr: 1.6530e-04
Epoch 40/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1967 - accuracy: 0.9369 - precision_1: 0.9539 - recall_1: 0.9207 - f1_score: 0.9368 - val_loss: 0.1012 - val_accuracy: 0.9696 - val_precision_1: 0.9806 - val_recall_1: 0.9616 - val_f1_score: 0.9711 - lr: 1.4957e-04
Epoch 41/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1869 - accuracy: 0.9383 - precision_1: 0.9557 - recall_1: 0.9249 - f1_score: 0.9398 - val_loss: 0.1006 - val_accuracy: 0.9707 - val_precision_1: 0.9809 - val_recall_1: 0.9614 - val_f1_score: 0.9711 - lr: 1.3534e-04
Epoch 42/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1871 - accuracy: 0.9378 - precision_1: 0.9557 - recall_1: 0.9246 - f1_score: 0.9397 - val_loss: 0.0978 - val_accuracy: 0.9721 - val_precision_1: 0.9820 - val_recall_1: 0.9631 - val_f1_score: 0.9726 - lr: 1.2246e-04
Epoch 43/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1783 - accuracy: 0.9422 - precision_1: 0.9581 - recall_1: 0.9286 - f1_score: 0.9429 - val_loss: 0.0987 - val_accuracy: 0.9707 - val_precision_1: 0.9808 - val_recall_1: 0.9630 - val_f1_score: 0.9719 - lr: 1.1080e-04
Epoch 44/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1769 - accuracy: 0.9409 - precision_1: 0.9579 - recall_1: 0.9269 - f1_score: 0.9420 - val_loss: 0.1005 - val_accuracy: 0.9697 - val_precision_1: 0.9804 - val_recall_1: 0.9628 - val_f1_score: 0.9716 - lr: 1.0026e-04
Epoch 45/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1749 - accuracy: 0.9433 - precision_1: 0.9594 - recall_1: 0.9293 - f1_score: 0.9440 - val_loss: 0.0993 - val_accuracy: 0.9700 - val_precision_1: 0.9804 - val_recall_1: 0.9626 - val_f1_score: 0.9715 - lr: 9.0718e-05
Epoch 46/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1757 - accuracy: 0.9428 - precision_1: 0.9582 - recall_1: 0.9295 - f1_score: 0.9435 - val_loss: 0.0978 - val_accuracy: 0.9714 - val_precision_1: 0.9813 - val_recall_1: 0.9633 - val_f1_score: 0.9723 - lr: 8.2085e-05
Epoch 47/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1713 - accuracy: 0.9441 - precision_1: 0.9595 - recall_1: 0.9318 - f1_score: 0.9454 - val_loss: 0.0965 - val_accuracy: 0.9713 - val_precision_1: 0.9815 - val_recall_1: 0.9633 - val_f1_score: 0.9724 - lr: 7.4274e-05
Epoch 48/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1651 - accuracy: 0.9458 - precision_1: 0.9605 - recall_1: 0.9338 - f1_score: 0.9468 - val_loss: 0.0963 - val_accuracy: 0.9717 - val_precision_1: 0.9809 - val_recall_1: 0.9640 - val_f1_score: 0.9725 - lr: 6.7206e-05
Epoch 49/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1766 - accuracy: 0.9426 - precision_1: 0.9584 - recall_1: 0.9305 - f1_score: 0.9442 - val_loss: 0.0951 - val_accuracy: 0.9721 - val_precision_1: 0.9813 - val_recall_1: 0.9639 - val_f1_score: 0.9726 - lr: 6.0810e-05
Epoch 50/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1694 - accuracy: 0.9434 - precision_1: 0.9580 - recall_1: 0.9304 - f1_score: 0.9439 - val_loss: 0.0957 - val_accuracy: 0.9716 - val_precision_1: 0.9813 - val_recall_1: 0.9649 - val_f1_score: 0.9731 - lr: 5.5023e-05
Epoch 51/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1641 - accuracy: 0.9445 - precision_1: 0.9585 - recall_1: 0.9326 - f1_score: 0.9452 - val_loss: 0.0949 - val_accuracy: 0.9709 - val_precision_1: 0.9807 - val_recall_1: 0.9647 - val_f1_score: 0.9727 - lr: 4.9787e-05
Epoch 52/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1639 - accuracy: 0.9459 - precision_1: 0.9614 - recall_1: 0.9334 - f1_score: 0.9470 - val_loss: 0.0949 - val_accuracy: 0.9717 - val_precision_1: 0.9811 - val_recall_1: 0.9652 - val_f1_score: 0.9732 - lr: 4.5049e-05
Epoch 53/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1671 - accuracy: 0.9452 - precision_1: 0.9600 - recall_1: 0.9343 - f1_score: 0.9469 - val_loss: 0.0946 - val_accuracy: 0.9718 - val_precision_1: 0.9816 - val_recall_1: 0.9649 - val_f1_score: 0.9732 - lr: 4.0762e-05
Epoch 54/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1615 - accuracy: 0.9461 - precision_1: 0.9605 - recall_1: 0.9342 - f1_score: 0.9470 - val_loss: 0.0947 - val_accuracy: 0.9718 - val_precision_1: 0.9809 - val_recall_1: 0.9651 - val_f1_score: 0.9731 - lr: 3.6883e-05
Epoch 55/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1623 - accuracy: 0.9461 - precision_1: 0.9593 - recall_1: 0.9342 - f1_score: 0.9465 - val_loss: 0.0949 - val_accuracy: 0.9714 - val_precision_1: 0.9809 - val_recall_1: 0.9651 - val_f1_score: 0.9731 - lr: 3.3373e-05
Epoch 56/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1540 - accuracy: 0.9494 - precision_1: 0.9624 - recall_1: 0.9385 - f1_score: 0.9502 - val_loss: 0.0950 - val_accuracy: 0.9718 - val_precision_1: 0.9818 - val_recall_1: 0.9645 - val_f1_score: 0.9732 - lr: 3.0197e-05
Epoch 57/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1613 - accuracy: 0.9462 - precision_1: 0.9617 - recall_1: 0.9352 - f1_score: 0.9481 - val_loss: 0.0943 - val_accuracy: 0.9716 - val_precision_1: 0.9807 - val_recall_1: 0.9654 - val_f1_score: 0.9731 - lr: 2.7324e-05
Epoch 58/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1549 - accuracy: 0.9488 - precision_1: 0.9625 - recall_1: 0.9374 - f1_score: 0.9496 - val_loss: 0.0940 - val_accuracy: 0.9728 - val_precision_1: 0.9817 - val_recall_1: 0.9656 - val_f1_score: 0.9737 - lr: 2.4724e-05
Epoch 59/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1589 - accuracy: 0.9464 - precision_1: 0.9607 - recall_1: 0.9351 - f1_score: 0.9476 - val_loss: 0.0942 - val_accuracy: 0.9729 - val_precision_1: 0.9817 - val_recall_1: 0.9656 - val_f1_score: 0.9737 - lr: 2.2371e-05
Epoch 60/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1507 - accuracy: 0.9503 - precision_1: 0.9636 - recall_1: 0.9391 - f1_score: 0.9511 - val_loss: 0.0940 - val_accuracy: 0.9726 - val_precision_1: 0.9816 - val_recall_1: 0.9657 - val_f1_score: 0.9737 - lr: 2.0242e-05
Epoch 61/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1593 - accuracy: 0.9473 - precision_1: 0.9609 - recall_1: 0.9359 - f1_score: 0.9480 - val_loss: 0.0935 - val_accuracy: 0.9723 - val_precision_1: 0.9815 - val_recall_1: 0.9659 - val_f1_score: 0.9737 - lr: 1.8316e-05
Epoch 62/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1497 - accuracy: 0.9493 - precision_1: 0.9641 - recall_1: 0.9381 - f1_score: 0.9508 - val_loss: 0.0933 - val_accuracy: 0.9723 - val_precision_1: 0.9812 - val_recall_1: 0.9659 - val_f1_score: 0.9736 - lr: 1.6573e-05
Epoch 63/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1547 - accuracy: 0.9493 - precision_1: 0.9625 - recall_1: 0.9373 - f1_score: 0.9496 - val_loss: 0.0936 - val_accuracy: 0.9722 - val_precision_1: 0.9806 - val_recall_1: 0.9659 - val_f1_score: 0.9733 - lr: 1.4996e-05
Epoch 64/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1576 - accuracy: 0.9475 - precision_1: 0.9619 - recall_1: 0.9366 - f1_score: 0.9490 - val_loss: 0.0937 - val_accuracy: 0.9723 - val_precision_1: 0.9808 - val_recall_1: 0.9654 - val_f1_score: 0.9731 - lr: 1.3569e-05
Epoch 65/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1566 - accuracy: 0.9481 - precision_1: 0.9613 - recall_1: 0.9369 - f1_score: 0.9488 - val_loss: 0.0933 - val_accuracy: 0.9719 - val_precision_1: 0.9806 - val_recall_1: 0.9656 - val_f1_score: 0.9731 - lr: 1.2277e-05
Epoch 66/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1533 - accuracy: 0.9510 - precision_1: 0.9638 - recall_1: 0.9387 - f1_score: 0.9510 - val_loss: 0.0937 - val_accuracy: 0.9714 - val_precision_1: 0.9807 - val_recall_1: 0.9654 - val_f1_score: 0.9731 - lr: 1.1109e-05
Epoch 67/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1605 - accuracy: 0.9456 - precision_1: 0.9602 - recall_1: 0.9342 - f1_score: 0.9469 - val_loss: 0.0932 - val_accuracy: 0.9724 - val_precision_1: 0.9815 - val_recall_1: 0.9659 - val_f1_score: 0.9737 - lr: 1.0052e-05
Epoch 68/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1584 - accuracy: 0.9466 - precision_1: 0.9602 - recall_1: 0.9353 - f1_score: 0.9475 - val_loss: 0.0935 - val_accuracy: 0.9719 - val_precision_1: 0.9813 - val_recall_1: 0.9657 - val_f1_score: 0.9736 - lr: 9.0953e-06
Epoch 69/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1505 - accuracy: 0.9511 - precision_1: 0.9648 - recall_1: 0.9400 - f1_score: 0.9521 - val_loss: 0.0931 - val_accuracy: 0.9723 - val_precision_1: 0.9813 - val_recall_1: 0.9656 - val_f1_score: 0.9735 - lr: 8.2297e-06
Epoch 70/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1536 - accuracy: 0.9494 - precision_1: 0.9632 - recall_1: 0.9382 - f1_score: 0.9504 - val_loss: 0.0936 - val_accuracy: 0.9721 - val_precision_1: 0.9811 - val_recall_1: 0.9660 - val_f1_score: 0.9736 - lr: 7.4466e-06
Epoch 71/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1583 - accuracy: 0.9483 - precision_1: 0.9613 - recall_1: 0.9363 - f1_score: 0.9486 - val_loss: 0.0932 - val_accuracy: 0.9723 - val_precision_1: 0.9813 - val_recall_1: 0.9654 - val_f1_score: 0.9734 - lr: 6.7379e-06
Epoch 72/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1625 - accuracy: 0.9471 - precision_1: 0.9618 - recall_1: 0.9351 - f1_score: 0.9482 - val_loss: 0.0932 - val_accuracy: 0.9721 - val_precision_1: 0.9815 - val_recall_1: 0.9656 - val_f1_score: 0.9736 - lr: 6.0967e-06
Epoch 73/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1509 - accuracy: 0.9502 - precision_1: 0.9638 - recall_1: 0.9380 - f1_score: 0.9506 - val_loss: 0.0932 - val_accuracy: 0.9719 - val_precision_1: 0.9812 - val_recall_1: 0.9659 - val_f1_score: 0.9736 - lr: 5.5166e-06
Epoch 74/100
645/645 [==============================] - 30s 46ms/step - loss: 0.1571 - accuracy: 0.9477 - precision_1: 0.9609 - recall_1: 0.9368 - f1_score: 0.9486 - val_loss: 0.0933 - val_accuracy: 0.9719 - val_precision_1: 0.9811 - val_recall_1: 0.9659 - val_f1_score: 0.9735 - lr: 4.9916e-06
Epoch 75/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1554 - accuracy: 0.9480 - precision_1: 0.9614 - recall_1: 0.9366 - f1_score: 0.9487 - val_loss: 0.0932 - val_accuracy: 0.9719 - val_precision_1: 0.9811 - val_recall_1: 0.9657 - val_f1_score: 0.9734 - lr: 4.5166e-06
Epoch 76/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1537 - accuracy: 0.9493 - precision_1: 0.9627 - recall_1: 0.9376 - f1_score: 0.9498 - val_loss: 0.0932 - val_accuracy: 0.9718 - val_precision_1: 0.9810 - val_recall_1: 0.9657 - val_f1_score: 0.9734 - lr: 4.0868e-06
Epoch 77/100
645/645 [==============================] - 31s 47ms/step - loss: 0.1522 - accuracy: 0.9503 - precision_1: 0.9637 - recall_1: 0.9400 - f1_score: 0.9516 - val_loss: 0.0930 - val_accuracy: 0.9718 - val_precision_1: 0.9808 - val_recall_1: 0.9659 - val_f1_score: 0.9734 - lr: 3.6979e-06
Epoch 78/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1573 - accuracy: 0.9488 - precision_1: 0.9626 - recall_1: 0.9381 - f1_score: 0.9501 - val_loss: 0.0930 - val_accuracy: 0.9719 - val_precision_1: 0.9810 - val_recall_1: 0.9659 - val_f1_score: 0.9734 - lr: 3.3460e-06
Epoch 79/100
645/645 [==============================] - 31s 47ms/step - loss: 0.1539 - accuracy: 0.9491 - precision_1: 0.9630 - recall_1: 0.9382 - f1_score: 0.9503 - val_loss: 0.0929 - val_accuracy: 0.9719 - val_precision_1: 0.9810 - val_recall_1: 0.9660 - val_f1_score: 0.9735 - lr: 3.0276e-06
Epoch 80/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1540 - accuracy: 0.9496 - precision_1: 0.9637 - recall_1: 0.9377 - f1_score: 0.9504 - val_loss: 0.0930 - val_accuracy: 0.9719 - val_precision_1: 0.9811 - val_recall_1: 0.9660 - val_f1_score: 0.9736 - lr: 2.7394e-06
Epoch 81/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1567 - accuracy: 0.9477 - precision_1: 0.9618 - recall_1: 0.9360 - f1_score: 0.9486 - val_loss: 0.0928 - val_accuracy: 0.9719 - val_precision_1: 0.9811 - val_recall_1: 0.9659 - val_f1_score: 0.9735 - lr: 2.4788e-06
Epoch 82/100
645/645 [==============================] - 31s 47ms/step - loss: 0.1558 - accuracy: 0.9486 - precision_1: 0.9628 - recall_1: 0.9382 - f1_score: 0.9503 - val_loss: 0.0926 - val_accuracy: 0.9721 - val_precision_1: 0.9813 - val_recall_1: 0.9660 - val_f1_score: 0.9737 - lr: 2.2429e-06
Epoch 83/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1544 - accuracy: 0.9483 - precision_1: 0.9618 - recall_1: 0.9373 - f1_score: 0.9493 - val_loss: 0.0927 - val_accuracy: 0.9722 - val_precision_1: 0.9815 - val_recall_1: 0.9664 - val_f1_score: 0.9739 - lr: 2.0294e-06
Epoch 84/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1515 - accuracy: 0.9483 - precision_1: 0.9610 - recall_1: 0.9376 - f1_score: 0.9491 - val_loss: 0.0928 - val_accuracy: 0.9722 - val_precision_1: 0.9815 - val_recall_1: 0.9662 - val_f1_score: 0.9739 - lr: 1.8363e-06
Epoch 85/100
645/645 [==============================] - 30s 47ms/step - loss: 0.1542 - accuracy: 0.9493 - precision_1: 0.9626 - recall_1: 0.9382 - f1_score: 0.9502 - val_loss: 0.0929 - val_accuracy: 0.9722 - val_precision_1: 0.9815 - val_recall_1: 0.9662 - val_f1_score: 0.9739 - lr: 1.6616e-06
Epoch 86/100
645/645 [==============================] - 31s 48ms/step - loss: 0.1524 - accuracy: 0.9486 - precision_1: 0.9625 - recall_1: 0.9377 - f1_score: 0.9499 - val_loss: 0.0928 - val_accuracy: 0.9723 - val_precision_1: 0.9813 - val_recall_1: 0.9662 - val_f1_score: 0.9738 - lr: 1.5034e-06
Epoch 87/100
645/645 [==============================] - 31s 48ms/step - loss: 0.1530 - accuracy: 0.9500 - precision_1: 0.9635 - recall_1: 0.9393 - f1_score: 0.9512 - val_loss: 0.0927 - val_accuracy: 0.9722 - val_precision_1: 0.9818 - val_recall_1: 0.9662 - val_f1_score: 0.9741 - lr: 1.3604e-06
Epoch 88/100
645/645 [==============================] - 31s 48ms/step - loss: 0.1557 - accuracy: 0.9492 - precision_1: 0.9626 - recall_1: 0.9372 - f1_score: 0.9496 - val_loss: 0.0927 - val_accuracy: 0.9721 - val_precision_1: 0.9817 - val_recall_1: 0.9664 - val_f1_score: 0.9741 - lr: 1.2309e-06
Epoch 89/100
645/645 [==============================] - 31s 48ms/step - loss: 0.1576 - accuracy: 0.9479 - precision_1: 0.9620 - recall_1: 0.9364 - f1_score: 0.9489 - val_loss: 0.0927 - val_accuracy: 0.9721 - val_precision_1: 0.9817 - val_recall_1: 0.9662 - val_f1_score: 0.9740 - lr: 1.1138e-06
Epoch 90/100
645/645 [==============================] - 31s 48ms/step - loss: 0.1488 - accuracy: 0.9511 - precision_1: 0.9636 - recall_1: 0.9399 - f1_score: 0.9513 - val_loss: 0.0927 - val_accuracy: 0.9719 - val_precision_1: 0.9816 - val_recall_1: 0.9661 - val_f1_score: 0.9739 - lr: 1.0078e-06
Epoch 91/100
645/645 [==============================] - 31s 48ms/step - loss: 0.1518 - accuracy: 0.9502 - precision_1: 0.9637 - recall_1: 0.9391 - f1_score: 0.9510 - val_loss: 0.0928 - val_accuracy: 0.9719 - val_precision_1: 0.9816 - val_recall_1: 0.9662 - val_f1_score: 0.9739 - lr: 9.1188e-07
Epoch 92/100
645/645 [==============================] - 31s 48ms/step - loss: 0.1509 - accuracy: 0.9504 - precision_1: 0.9642 - recall_1: 0.9387 - f1_score: 0.9511 - val_loss: 0.0927 - val_accuracy: 0.9721 - val_precision_1: 0.9816 - val_recall_1: 0.9662 - val_f1_score: 0.9739 - lr: 8.2511e-07
Epoch 93/100
645/645 [==============================] - 31s 48ms/step - loss: 0.1508 - accuracy: 0.9503 - precision_1: 0.9632 - recall_1: 0.9384 - f1_score: 0.9505 - val_loss: 0.0927 - val_accuracy: 0.9722 - val_precision_1: 0.9816 - val_recall_1: 0.9662 - val_f1_score: 0.9739 - lr: 7.4659e-07
Epoch 94/100
645/645 [==============================] - 31s 47ms/step - loss: 0.1521 - accuracy: 0.9491 - precision_1: 0.9634 - recall_1: 0.9376 - f1_score: 0.9502 - val_loss: 0.0927 - val_accuracy: 0.9718 - val_precision_1: 0.9815 - val_recall_1: 0.9662 - val_f1_score: 0.9739 - lr: 6.7554e-07
Epoch 95/100
645/645 [==============================] - 31s 48ms/step - loss: 0.1526 - accuracy: 0.9488 - precision_1: 0.9629 - recall_1: 0.9381 - f1_score: 0.9502 - val_loss: 0.0927 - val_accuracy: 0.9721 - val_precision_1: 0.9816 - val_recall_1: 0.9662 - val_f1_score: 0.9739 - lr: 6.1125e-07
Epoch 96/100
645/645 [==============================] - 31s 48ms/step - loss: 0.1532 - accuracy: 0.9479 - precision_1: 0.9618 - recall_1: 0.9377 - f1_score: 0.9495 - val_loss: 0.0927 - val_accuracy: 0.9723 - val_precision_1: 0.9817 - val_recall_1: 0.9664 - val_f1_score: 0.9741 - lr: 5.5308e-07
Epoch 97/100
645/645 [==============================] - 31s 49ms/step - loss: 0.1543 - accuracy: 0.9486 - precision_1: 0.9632 - recall_1: 0.9367 - f1_score: 0.9496 - val_loss: 0.0927 - val_accuracy: 0.9721 - val_precision_1: 0.9817 - val_recall_1: 0.9662 - val_f1_score: 0.9740 - lr: 5.0045e-07
Elapsed time: 0:49.21666666666667:13.11