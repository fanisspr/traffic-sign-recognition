Results saved to: ./data/00010-val-train
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 48, 48, 3)]  0           []                               
                                                                                                  
 data_augmentation (Sequential)  (None, 48, 48, 3)   0           ['input_1[0][0]']                
                                                                                                  
 patches_1 (Patches)            (None, None, 48)     0           ['data_augmentation[0][0]']      
                                                                                                  
 patch_encoder (PatchEncoder)   (None, 144, 32)      6176        ['patches_1[0][0]']              
                                                                                                  
 layer_normalization (LayerNorm  (None, 144, 32)     64          ['patch_encoder[0][0]']          
 alization)                                                                                       
                                                                                                  
 multi_head_attention (MultiHea  (None, 144, 32)     25184       ['layer_normalization[0][0]',    
 dAttention)                                                      'layer_normalization[0][0]']    
                                                                                                  
 add (Add)                      (None, 144, 32)      0           ['multi_head_attention[0][0]',   
                                                                  'patch_encoder[0][0]']          
                                                                                                  
 layer_normalization_1 (LayerNo  (None, 144, 32)     64          ['add[0][0]']                    
 rmalization)                                                                                     
                                                                                                  
 dense_1 (Dense)                (None, 144, 64)      2112        ['layer_normalization_1[0][0]']  
                                                                                                  
 dropout (Dropout)              (None, 144, 64)      0           ['dense_1[0][0]']                
                                                                                                  
 dense_2 (Dense)                (None, 144, 32)      2080        ['dropout[0][0]']                
                                                                                                  
 dropout_1 (Dropout)            (None, 144, 32)      0           ['dense_2[0][0]']                
                                                                                                  
 add_1 (Add)                    (None, 144, 32)      0           ['dropout_1[0][0]',              
                                                                  'add[0][0]']                    
                                                                                                  
 layer_normalization_2 (LayerNo  (None, 144, 32)     64          ['add_1[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_1 (MultiH  (None, 144, 32)     25184       ['layer_normalization_2[0][0]',  
 eadAttention)                                                    'layer_normalization_2[0][0]']  
                                                                                                  
 add_2 (Add)                    (None, 144, 32)      0           ['multi_head_attention_1[0][0]', 
                                                                  'add_1[0][0]']                  
                                                                                                  
 layer_normalization_3 (LayerNo  (None, 144, 32)     64          ['add_2[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_3 (Dense)                (None, 144, 64)      2112        ['layer_normalization_3[0][0]']  
                                                                                                  
 dropout_2 (Dropout)            (None, 144, 64)      0           ['dense_3[0][0]']                
                                                                                                  
 dense_4 (Dense)                (None, 144, 32)      2080        ['dropout_2[0][0]']              
                                                                                                  
 dropout_3 (Dropout)            (None, 144, 32)      0           ['dense_4[0][0]']                
                                                                                                  
 add_3 (Add)                    (None, 144, 32)      0           ['dropout_3[0][0]',              
                                                                  'add_2[0][0]']                  
                                                                                                  
 layer_normalization_4 (LayerNo  (None, 144, 32)     64          ['add_3[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_2 (MultiH  (None, 144, 32)     25184       ['layer_normalization_4[0][0]',  
 eadAttention)                                                    'layer_normalization_4[0][0]']  
                                                                                                  
 add_4 (Add)                    (None, 144, 32)      0           ['multi_head_attention_2[0][0]', 
                                                                  'add_3[0][0]']                  
                                                                                                  
 layer_normalization_5 (LayerNo  (None, 144, 32)     64          ['add_4[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_5 (Dense)                (None, 144, 64)      2112        ['layer_normalization_5[0][0]']  
                                                                                                  
 dropout_4 (Dropout)            (None, 144, 64)      0           ['dense_5[0][0]']                
                                                                                                  
 dense_6 (Dense)                (None, 144, 32)      2080        ['dropout_4[0][0]']              
                                                                                                  
 dropout_5 (Dropout)            (None, 144, 32)      0           ['dense_6[0][0]']                
                                                                                                  
 add_5 (Add)                    (None, 144, 32)      0           ['dropout_5[0][0]',              
                                                                  'add_4[0][0]']                  
                                                                                                  
 layer_normalization_6 (LayerNo  (None, 144, 32)     64          ['add_5[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_3 (MultiH  (None, 144, 32)     25184       ['layer_normalization_6[0][0]',  
 eadAttention)                                                    'layer_normalization_6[0][0]']  
                                                                                                  
 add_6 (Add)                    (None, 144, 32)      0           ['multi_head_attention_3[0][0]', 
                                                                  'add_5[0][0]']                  
                                                                                                  
 layer_normalization_7 (LayerNo  (None, 144, 32)     64          ['add_6[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_7 (Dense)                (None, 144, 64)      2112        ['layer_normalization_7[0][0]']  
                                                                                                  
 dropout_6 (Dropout)            (None, 144, 64)      0           ['dense_7[0][0]']                
                                                                                                  
 dense_8 (Dense)                (None, 144, 32)      2080        ['dropout_6[0][0]']              
                                                                                                  
 dropout_7 (Dropout)            (None, 144, 32)      0           ['dense_8[0][0]']                
                                                                                                  
 add_7 (Add)                    (None, 144, 32)      0           ['dropout_7[0][0]',              
                                                                  'add_6[0][0]']                  
                                                                                                  
 layer_normalization_8 (LayerNo  (None, 144, 32)     64          ['add_7[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 flatten (Flatten)              (None, 4608)         0           ['layer_normalization_8[0][0]']  
                                                                                                  
 dropout_8 (Dropout)            (None, 4608)         0           ['flatten[0][0]']                
                                                                                                  
 dense_9 (Dense)                (None, 512)          2359808     ['dropout_8[0][0]']              
                                                                                                  
 dropout_9 (Dropout)            (None, 512)          0           ['dense_9[0][0]']                
                                                                                                  
 dense_10 (Dense)               (None, 256)          131328      ['dropout_9[0][0]']              
                                                                                                  
 dropout_10 (Dropout)           (None, 256)          0           ['dense_10[0][0]']               
                                                                                                  
 dense_11 (Dense)               (None, 43)           11051       ['dropout_10[0][0]']             
                                                                                                  
==================================================================================================
Total params: 2,626,443
Trainable params: 2,626,443
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
628/628 [==============================] - 37s 49ms/step - loss: 2.2430 - accuracy: 0.3626 - precision: 0.7699 - recall: 0.2137 - f1_score: 0.3031 - val_loss: 0.7251 - val_accuracy: 0.7839 - val_precision: 0.9410 - val_recall: 0.6242 - val_f1_score: 0.7488 - lr: 0.0100
Epoch 2/100
628/628 [==============================] - 30s 47ms/step - loss: 0.8858 - accuracy: 0.7170 - precision: 0.8472 - recall: 0.6085 - f1_score: 0.7052 - val_loss: 0.3063 - val_accuracy: 0.9115 - val_precision: 0.9529 - val_recall: 0.8592 - val_f1_score: 0.9032 - lr: 0.0100
Epoch 3/100
628/628 [==============================] - 30s 48ms/step - loss: 0.5822 - accuracy: 0.8142 - precision: 0.8877 - recall: 0.7468 - f1_score: 0.8103 - val_loss: 0.1986 - val_accuracy: 0.9459 - val_precision: 0.9729 - val_recall: 0.9214 - val_f1_score: 0.9462 - lr: 0.0100
Epoch 4/100
628/628 [==============================] - 30s 47ms/step - loss: 0.4482 - accuracy: 0.8575 - precision: 0.9072 - recall: 0.8107 - f1_score: 0.8557 - val_loss: 0.1326 - val_accuracy: 0.9647 - val_precision: 0.9801 - val_recall: 0.9490 - val_f1_score: 0.9641 - lr: 0.0100
Epoch 5/100
628/628 [==============================] - 30s 47ms/step - loss: 0.3648 - accuracy: 0.8873 - precision: 0.9245 - recall: 0.8495 - f1_score: 0.8851 - val_loss: 0.1088 - val_accuracy: 0.9694 - val_precision: 0.9832 - val_recall: 0.9603 - val_f1_score: 0.9714 - lr: 0.0100
Epoch 6/100
628/628 [==============================] - 30s 47ms/step - loss: 0.3170 - accuracy: 0.9000 - precision: 0.9329 - recall: 0.8704 - f1_score: 0.9003 - val_loss: 0.0872 - val_accuracy: 0.9758 - val_precision: 0.9856 - val_recall: 0.9686 - val_f1_score: 0.9769 - lr: 0.0100
Epoch 7/100
628/628 [==============================] - 30s 47ms/step - loss: 0.2819 - accuracy: 0.9125 - precision: 0.9394 - recall: 0.8855 - f1_score: 0.9113 - val_loss: 0.0756 - val_accuracy: 0.9821 - val_precision: 0.9886 - val_recall: 0.9750 - val_f1_score: 0.9817 - lr: 0.0100
Epoch 8/100
628/628 [==============================] - 30s 47ms/step - loss: 0.2474 - accuracy: 0.9236 - precision: 0.9451 - recall: 0.9019 - f1_score: 0.9228 - val_loss: 0.0693 - val_accuracy: 0.9824 - val_precision: 0.9882 - val_recall: 0.9759 - val_f1_score: 0.9820 - lr: 0.0100
Epoch 9/100
628/628 [==============================] - 30s 47ms/step - loss: 0.2282 - accuracy: 0.9300 - precision: 0.9514 - recall: 0.9095 - f1_score: 0.9298 - val_loss: 0.0625 - val_accuracy: 0.9842 - val_precision: 0.9905 - val_recall: 0.9795 - val_f1_score: 0.9848 - lr: 0.0100
Epoch 10/100
628/628 [==============================] - 30s 47ms/step - loss: 0.2055 - accuracy: 0.9360 - precision: 0.9549 - recall: 0.9175 - f1_score: 0.9357 - val_loss: 0.0619 - val_accuracy: 0.9844 - val_precision: 0.9901 - val_recall: 0.9792 - val_f1_score: 0.9845 - lr: 0.0100
Epoch 11/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1979 - accuracy: 0.9390 - precision: 0.9567 - recall: 0.9219 - f1_score: 0.9388 - val_loss: 0.0477 - val_accuracy: 0.9875 - val_precision: 0.9915 - val_recall: 0.9838 - val_f1_score: 0.9876 - lr: 0.0100
Epoch 12/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1886 - accuracy: 0.9419 - precision: 0.9577 - recall: 0.9258 - f1_score: 0.9413 - val_loss: 0.0491 - val_accuracy: 0.9852 - val_precision: 0.9909 - val_recall: 0.9824 - val_f1_score: 0.9866 - lr: 0.0100
Epoch 13/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1781 - accuracy: 0.9444 - precision: 0.9597 - recall: 0.9293 - f1_score: 0.9441 - val_loss: 0.0427 - val_accuracy: 0.9879 - val_precision: 0.9925 - val_recall: 0.9851 - val_f1_score: 0.9888 - lr: 0.0100
Epoch 14/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1698 - accuracy: 0.9480 - precision: 0.9625 - recall: 0.9331 - f1_score: 0.9475 - val_loss: 0.0415 - val_accuracy: 0.9884 - val_precision: 0.9938 - val_recall: 0.9851 - val_f1_score: 0.9894 - lr: 0.0100
Epoch 15/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1622 - accuracy: 0.9499 - precision: 0.9636 - recall: 0.9363 - f1_score: 0.9497 - val_loss: 0.0394 - val_accuracy: 0.9894 - val_precision: 0.9936 - val_recall: 0.9875 - val_f1_score: 0.9905 - lr: 0.0100
Epoch 16/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1553 - accuracy: 0.9525 - precision: 0.9645 - recall: 0.9393 - f1_score: 0.9517 - val_loss: 0.0356 - val_accuracy: 0.9913 - val_precision: 0.9944 - val_recall: 0.9879 - val_f1_score: 0.9910 - lr: 0.0100
Epoch 17/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1505 - accuracy: 0.9557 - precision: 0.9681 - recall: 0.9426 - f1_score: 0.9551 - val_loss: 0.0400 - val_accuracy: 0.9908 - val_precision: 0.9943 - val_recall: 0.9871 - val_f1_score: 0.9907 - lr: 0.0100
Epoch 18/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1543 - accuracy: 0.9514 - precision: 0.9649 - recall: 0.9387 - f1_score: 0.9514 - val_loss: 0.0339 - val_accuracy: 0.9911 - val_precision: 0.9951 - val_recall: 0.9888 - val_f1_score: 0.9919 - lr: 0.0100
Epoch 19/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1463 - accuracy: 0.9565 - precision: 0.9677 - recall: 0.9448 - f1_score: 0.9560 - val_loss: 0.0493 - val_accuracy: 0.9879 - val_precision: 0.9944 - val_recall: 0.9818 - val_f1_score: 0.9880 - lr: 0.0100
Epoch 20/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1406 - accuracy: 0.9577 - precision: 0.9688 - recall: 0.9466 - f1_score: 0.9574 - val_loss: 0.0345 - val_accuracy: 0.9916 - val_precision: 0.9946 - val_recall: 0.9898 - val_f1_score: 0.9922 - lr: 0.0100
Epoch 21/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1362 - accuracy: 0.9574 - precision: 0.9694 - recall: 0.9461 - f1_score: 0.9575 - val_loss: 0.0365 - val_accuracy: 0.9911 - val_precision: 0.9950 - val_recall: 0.9881 - val_f1_score: 0.9915 - lr: 0.0100
Epoch 22/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1316 - accuracy: 0.9597 - precision: 0.9703 - recall: 0.9490 - f1_score: 0.9594 - val_loss: 0.0313 - val_accuracy: 0.9911 - val_precision: 0.9940 - val_recall: 0.9889 - val_f1_score: 0.9914 - lr: 0.0090
Epoch 23/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1196 - accuracy: 0.9646 - precision: 0.9735 - recall: 0.9542 - f1_score: 0.9636 - val_loss: 0.0302 - val_accuracy: 0.9923 - val_precision: 0.9951 - val_recall: 0.9887 - val_f1_score: 0.9918 - lr: 0.0082
Epoch 24/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1148 - accuracy: 0.9666 - precision: 0.9755 - recall: 0.9568 - f1_score: 0.9660 - val_loss: 0.0350 - val_accuracy: 0.9902 - val_precision: 0.9937 - val_recall: 0.9872 - val_f1_score: 0.9904 - lr: 0.0074
Epoch 25/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1106 - accuracy: 0.9658 - precision: 0.9752 - recall: 0.9562 - f1_score: 0.9655 - val_loss: 0.0302 - val_accuracy: 0.9921 - val_precision: 0.9949 - val_recall: 0.9892 - val_f1_score: 0.9920 - lr: 0.0067
Epoch 26/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1076 - accuracy: 0.9698 - precision: 0.9777 - recall: 0.9594 - f1_score: 0.9684 - val_loss: 0.0270 - val_accuracy: 0.9934 - val_precision: 0.9959 - val_recall: 0.9909 - val_f1_score: 0.9934 - lr: 0.0061
Epoch 27/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1056 - accuracy: 0.9685 - precision: 0.9770 - recall: 0.9589 - f1_score: 0.9678 - val_loss: 0.0268 - val_accuracy: 0.9941 - val_precision: 0.9968 - val_recall: 0.9918 - val_f1_score: 0.9943 - lr: 0.0055
Epoch 28/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1044 - accuracy: 0.9691 - precision: 0.9780 - recall: 0.9598 - f1_score: 0.9687 - val_loss: 0.0279 - val_accuracy: 0.9932 - val_precision: 0.9963 - val_recall: 0.9908 - val_f1_score: 0.9935 - lr: 0.0050
Epoch 29/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1003 - accuracy: 0.9714 - precision: 0.9793 - recall: 0.9606 - f1_score: 0.9698 - val_loss: 0.0248 - val_accuracy: 0.9938 - val_precision: 0.9969 - val_recall: 0.9923 - val_f1_score: 0.9946 - lr: 0.0045
Epoch 30/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1065 - accuracy: 0.9689 - precision: 0.9782 - recall: 0.9587 - f1_score: 0.9682 - val_loss: 0.0293 - val_accuracy: 0.9945 - val_precision: 0.9981 - val_recall: 0.9922 - val_f1_score: 0.9951 - lr: 0.0041
Epoch 31/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1078 - accuracy: 0.9700 - precision: 0.9792 - recall: 0.9584 - f1_score: 0.9686 - val_loss: 0.0285 - val_accuracy: 0.9925 - val_precision: 0.9964 - val_recall: 0.9907 - val_f1_score: 0.9935 - lr: 0.0037
Epoch 32/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1074 - accuracy: 0.9697 - precision: 0.9790 - recall: 0.9589 - f1_score: 0.9687 - val_loss: 0.0350 - val_accuracy: 0.9931 - val_precision: 0.9961 - val_recall: 0.9894 - val_f1_score: 0.9927 - lr: 0.0033
Epoch 33/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1100 - accuracy: 0.9699 - precision: 0.9791 - recall: 0.9579 - f1_score: 0.9683 - val_loss: 0.0288 - val_accuracy: 0.9932 - val_precision: 0.9974 - val_recall: 0.9907 - val_f1_score: 0.9940 - lr: 0.0030
Epoch 34/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1153 - accuracy: 0.9695 - precision: 0.9790 - recall: 0.9558 - f1_score: 0.9671 - val_loss: 0.0316 - val_accuracy: 0.9944 - val_precision: 0.9977 - val_recall: 0.9909 - val_f1_score: 0.9943 - lr: 0.0027
Epoch 35/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1192 - accuracy: 0.9686 - precision: 0.9792 - recall: 0.9544 - f1_score: 0.9666 - val_loss: 0.0342 - val_accuracy: 0.9923 - val_precision: 0.9960 - val_recall: 0.9895 - val_f1_score: 0.9927 - lr: 0.0025
Epoch 36/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1206 - accuracy: 0.9682 - precision: 0.9790 - recall: 0.9530 - f1_score: 0.9658 - val_loss: 0.0331 - val_accuracy: 0.9941 - val_precision: 0.9974 - val_recall: 0.9903 - val_f1_score: 0.9938 - lr: 0.0022
Epoch 37/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1279 - accuracy: 0.9679 - precision: 0.9788 - recall: 0.9514 - f1_score: 0.9647 - val_loss: 0.0366 - val_accuracy: 0.9925 - val_precision: 0.9972 - val_recall: 0.9888 - val_f1_score: 0.9929 - lr: 0.0020
Epoch 38/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1312 - accuracy: 0.9669 - precision: 0.9787 - recall: 0.9496 - f1_score: 0.9638 - val_loss: 0.0452 - val_accuracy: 0.9915 - val_precision: 0.9970 - val_recall: 0.9856 - val_f1_score: 0.9912 - lr: 0.0018
Epoch 39/100
628/628 [==============================] - 30s 47ms/step - loss: 0.1406 - accuracy: 0.9638 - precision: 0.9779 - recall: 0.9450 - f1_score: 0.9610 - val_loss: 0.0403 - val_accuracy: 0.9921 - val_precision: 0.9965 - val_recall: 0.9887 - val_f1_score: 0.9925 - lr: 0.0017
Epoch 40/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1451 - accuracy: 0.9648 - precision: 0.9795 - recall: 0.9434 - f1_score: 0.9609 - val_loss: 0.0435 - val_accuracy: 0.9913 - val_precision: 0.9970 - val_recall: 0.9872 - val_f1_score: 0.9920 - lr: 0.0015
Epoch 41/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1567 - accuracy: 0.9618 - precision: 0.9786 - recall: 0.9392 - f1_score: 0.9582 - val_loss: 0.0534 - val_accuracy: 0.9929 - val_precision: 0.9975 - val_recall: 0.9848 - val_f1_score: 0.9911 - lr: 0.0014
Epoch 42/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1632 - accuracy: 0.9593 - precision: 0.9778 - recall: 0.9339 - f1_score: 0.9551 - val_loss: 0.0545 - val_accuracy: 0.9917 - val_precision: 0.9973 - val_recall: 0.9855 - val_f1_score: 0.9913 - lr: 0.0012
Epoch 43/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1696 - accuracy: 0.9594 - precision: 0.9787 - recall: 0.9327 - f1_score: 0.9549 - val_loss: 0.0572 - val_accuracy: 0.9912 - val_precision: 0.9970 - val_recall: 0.9850 - val_f1_score: 0.9909 - lr: 0.0011
Epoch 44/100
628/628 [==============================] - 29s 47ms/step - loss: 0.1878 - accuracy: 0.9551 - precision: 0.9757 - recall: 0.9253 - f1_score: 0.9497 - val_loss: 0.0612 - val_accuracy: 0.9911 - val_precision: 0.9974 - val_recall: 0.9829 - val_f1_score: 0.9900 - lr: 0.0010
Elapsed time: 0:21.8:48.02